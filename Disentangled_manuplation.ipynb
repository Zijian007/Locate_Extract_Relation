{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import ModelAndTokenizer, plot_scores, find_token_range\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from causal_trace import plot_all_flow\n",
    "import os, re, json\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"  \n",
    "device = \"cuda:7\"\n",
    "mt = ModelAndTokenizer(model_name, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case1 (Country) (Capital,Currency,Area,Population,Religion,Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Location by CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 8\n",
    "data_path = \"/home/zijianwang/ACL2024/country_capital_city.json\"\n",
    "with open(data_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "Template = data[\"Prompt\"]\n",
    "relation = data[\"Relation\"]\n",
    "subject = data[\"samples\"][id][\"subject\"]\n",
    "object = data[\"samples\"][id][\"object\"]\n",
    "print(f\"Subject: {subject}, Relation: {relation}, Object: {object}\")\n",
    "print(Template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_prompt = Template.format(subject)\n",
    "token_range_sub = find_token_range(mt.tokenizer, Recall_prompt, subject)\n",
    "token_range_rel = find_token_range(mt.tokenizer, Recall_prompt, relation)\n",
    "# token_range_rel[1] = token_range_rel[1] + 3\n",
    "\n",
    "res_dict_no_rel = plot_all_flow(mt, Recall_prompt, subject = None, noise = 1, type = None, noise_range = token_range_rel)\n",
    "print(\"--------------------------------------------------\")\n",
    "res_dict_no_sub  = plot_all_flow(mt, Recall_prompt, subject = None, noise = 1, type = None, noise_range = token_range_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_no_rel = res_dict_no_rel[\"hs\"]['scores'][-1]\n",
    "score_no_sub = res_dict_no_sub[\"hs\"]['scores'][-1]\n",
    "# score_no_instructs.append(score_no_instruct)\n",
    "# score_no_inputs.append(score_no_input)\n",
    "title = f\"Mediating effect of subject and relation at last token, {Recall_prompt}\"\n",
    "plot_scores(score_no_rel, score_no_sub, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.abs(score_no_rel - score_no_sub)\n",
    "threshold = 0.4\n",
    "big_diff_mask = diff > threshold\n",
    "start_idx = torch.where(big_diff_mask)[0][0] if torch.any(big_diff_mask) else None\n",
    "end_idx = torch.where(big_diff_mask)[0][-1]  if torch.any(big_diff_mask) else None\n",
    "Range = (int(start_idx), int(end_idx))\n",
    "if start_idx is None or end_idx is None:\n",
    "    print(\"No Relation Emergence Stage Found (diff > threshold)!\")\n",
    "else:\n",
    "    print(f\"Relation Emergence Stage: {Range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.locating_extracting import zero_shot, edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_zs, acc_full, good_cases = zero_shot(mt, data_path, Recall_prompt, layer_range = Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "goog_cases_path = \"good_cases_{}.pkl\".format(data[\"name\"])\n",
    "with open(goog_cases_path , 'wb') as f:\n",
    "    pickle.dump(good_cases, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = pickle.load(open(goog_cases_path, \"rb\"))\n",
    "print(good_data)\n",
    "print(len(good_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = edit(mt, good_data, Recall_prompt, relation, layer_range = Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# generate observed data\n",
    "X = st.norm(loc=3, scale=1).rvs(size=1000)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# generate observed data\n",
    "X = st.norm(loc=3, scale=1).rvs(size=1000)\n",
    "print(X)\n",
    "\n",
    "def guassian_posterior(X, theta):\n",
    "    # returns the unnormalized log posterior\n",
    "    loglik = np.sum(np.log(st.norm(loc=theta, scale=1).pdf(X)))\n",
    "    logprior = np.log(st.norm(loc=0, scale=1).pdf(theta))\n",
    "    \n",
    "    return loglik + logprior\n",
    "    \n",
    "def guassian_proposal(theta_curr):\n",
    "    # proposal based on Gaussian\n",
    "    theta_new = st.norm(loc=theta_curr, scale=0.2).rvs()\n",
    "    return theta_new\n",
    "\n",
    "def guassian_proposal_prob(x1, x2):\n",
    "    # calculate proposal probability q(x2|x1), based on Gaussian\n",
    "    q = st.norm(loc=x1, scale=1).pdf(x2)\n",
    "    return q\n",
    "\n",
    "def mcmc_mh_posterior(X, theta_init, func, proposal_func, proposal_func_prob, n_iter=1000):\n",
    "    # Metropolis-Hastings to estimate posterior\n",
    "    thetas = []\n",
    "    theta_curr = theta_init\n",
    "    accept_rates = []\n",
    "    accept_cum = 0\n",
    "    \n",
    "    for i in range(1, n_iter+1):\n",
    "        theta_new = proposal_func(theta_curr)\n",
    "        \n",
    "        prob_curr = func(X, theta_curr)\n",
    "        prob_new = func(X, theta_new)\n",
    "        \n",
    "        # we calculate the prob=exp(x) only when prob<1 so the exp(x) will not overflow for large x\n",
    "        if prob_new > prob_curr:\n",
    "            acceptance_ratio = 1\n",
    "        else:\n",
    "            qr = proposal_func_prob(theta_curr, theta_new)/proposal_func_prob(theta_new, theta_curr)\n",
    "            acceptance_ratio = np.exp(prob_new - prob_curr) * qr\n",
    "        acceptance_prob = min(1, acceptance_ratio)\n",
    "        \n",
    "        if acceptance_prob > st.uniform(0,1).rvs():\n",
    "            print(\"Accept\")\n",
    "            theta_curr = theta_new\n",
    "            accept_cum = accept_cum+1\n",
    "            thetas.append(theta_new)\n",
    "        else:\n",
    "            print(\"Reject\")\n",
    "            thetas.append(theta_curr)\n",
    "            \n",
    "        accept_rates.append(accept_cum/i)\n",
    "        \n",
    "    return thetas, accept_rates\n",
    "\n",
    "# run MCMC\n",
    "thetas, accept_rates = mcmc_mh_posterior(X, 1, \n",
    "                                         guassian_posterior, guassian_proposal, guassian_proposal_prob, \n",
    "                                         n_iter=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# generate observed data from a mixture of two Gaussians\n",
    "X = np.concatenate([\n",
    "    st.norm(loc=10, scale=0.6).rvs(size=500),\n",
    "    st.norm(loc=1, scale=0.7).rvs(size=500)\n",
    "])\n",
    "\n",
    "print(X)\n",
    "\n",
    "def mixture_posterior(X, theta):\n",
    "    # returns the unnormalized log posterior\n",
    "    loglik1 = np.sum(np.log(st.norm(loc=theta[0], scale=1).pdf(X)))\n",
    "    loglik2 = np.sum(np.log(st.norm(loc=theta[1], scale=1).pdf(X)))\n",
    "    loglik = np.logaddexp(loglik1, loglik2) - np.log(2)\n",
    "    logprior = np.sum(np.log(st.norm(loc=0, scale=3).pdf(theta)))\n",
    "    return loglik + logprior\n",
    "\n",
    "def mixture_proposal(theta_curr):\n",
    "    # proposal based on Gaussian\n",
    "    theta_new = st.multivariate_normal(mean=theta_curr, cov=0.5*np.eye(2)).rvs()\n",
    "    return theta_new\n",
    "\n",
    "def mixture_proposal_prob(x1, x2):\n",
    "    # calculate proposal probability q(x2|x1), based on Gaussian\n",
    "    q = st.multivariate_normal(mean=x1, cov=0.5*np.eye(2)).pdf(x2)\n",
    "    return q\n",
    "\n",
    "def mcmc_mh_posterior(X, theta_init, func, proposal_func, proposal_func_prob, n_iter=1000):\n",
    "    # Metropolis-Hastings to estimate posterior\n",
    "    thetas = []\n",
    "    theta_curr = theta_init\n",
    "    accept_rates = []\n",
    "    accept_cum = 0\n",
    "\n",
    "    for i in range(1, n_iter+1):\n",
    "        theta_new = proposal_func(theta_curr)\n",
    "        prob_curr = func(X, theta_curr)\n",
    "        prob_new = func(X, theta_new)\n",
    "\n",
    "        # we calculate the prob=exp(x) only when prob<1 so the exp(x) will not overflow for large x\n",
    "        if prob_new > prob_curr:\n",
    "            acceptance_ratio = 1\n",
    "        else:\n",
    "            qr = proposal_func_prob(theta_curr, theta_new)/proposal_func_prob(theta_new, theta_curr)\n",
    "            acceptance_ratio = np.exp(prob_new - prob_curr) * qr\n",
    "\n",
    "        acceptance_prob = min(1, acceptance_ratio)\n",
    "\n",
    "        if acceptance_prob > st.uniform(0,1).rvs():\n",
    "            print(\"Accept\")\n",
    "            theta_curr = theta_new\n",
    "            accept_cum = accept_cum+1\n",
    "        else:\n",
    "            print(\"Reject\")\n",
    "\n",
    "        thetas.append(theta_curr)\n",
    "        accept_rates.append(accept_cum/i)\n",
    "\n",
    "    return thetas, accept_rates\n",
    "\n",
    "# run MCMC\n",
    "thetas, accept_rates = mcmc_mh_posterior(X, [0, 0],\n",
    "                                         mixture_posterior, mixture_proposal, mixture_proposal_prob,\n",
    "                                         n_iter=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thetas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
